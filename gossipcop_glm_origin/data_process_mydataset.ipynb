{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:45.860950Z",
     "start_time": "2024-08-07T05:28:45.858269Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import os\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:47.323937Z",
     "start_time": "2024-08-07T05:28:45.863229Z"
    }
   },
   "source": [
    "print(os.getcwd())\n",
    "style_fake_data = pd.read_json(\"./gossipcop_v3_keep_data_in_proper_length.json\",orient='index')\n",
    "type(style_fake_data[:20].index)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/wdnmd/PycharmProjects/CSFND_yanjie/gossipcop_glm_origin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:47.332550Z",
     "start_time": "2024-08-07T05:28:47.325562Z"
    }
   },
   "source": "style_fake_data['label'].value_counts()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    11945\n",
       "fake     3784\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:50.773444Z",
     "start_time": "2024-08-07T05:28:47.333564Z"
    }
   },
   "source": [
    "def get_all_top_image_id(image_dir_path):\n",
    "    suffix_to_remove = '_top_img.png'\n",
    "    all_items  = os.listdir(image_dir_path)\n",
    "    top_image_ids = {item.rstrip(suffix_to_remove) for item in all_items if os.path.isfile(os.path.join(image_dir_path, item)) and item.endswith(suffix_to_remove)}\n",
    "    return top_image_ids\n",
    "\n",
    "def filter_data(data,image_dir_path):\n",
    "    top_image_ids = get_all_top_image_id(image_dir_path)\n",
    "    print(len(top_image_ids))\n",
    "    has_top_img_list = [id in top_image_ids for id in data.id]\n",
    "    return data[has_top_img_list]\n",
    "    \n",
    "filter_data = filter_data(style_fake_data,'top_img')\n",
    "# 2.只保留ID  文本内容 标签\n",
    "keep_features = [\"id\",\"text\",\"label\"]\n",
    "keep_data = filter_data[keep_features]\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4699\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:50.779817Z",
     "start_time": "2024-08-07T05:28:50.775136Z"
    }
   },
   "source": "keep_data['label'].value_counts()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    4376\n",
       "fake     323\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:50.799845Z",
     "start_time": "2024-08-07T05:28:50.780922Z"
    }
   },
   "source": [
    "def split_data(data):\n",
    "    # 3. 保存到文件中，文本和图像一一对应。\n",
    "    # 划分训练和测试数据集，要求训练集和测试集中的正负类的分布差不多，\n",
    "    # 其中 文本 ID 和图像ID一致，也对应上文本的存储位置。\n",
    "    df_shuffled = data.sample(frac=1.0, random_state=42)\n",
    "    \n",
    "    # 计算训练集和测试集的数量\n",
    "    num_train_samples = 80\n",
    "    num_val_samples = 80\n",
    "    num_test_samples = len(df_shuffled) - 160\n",
    "    \n",
    "    \n",
    "    # 分割数据集\n",
    "    \n",
    "    train_set = df_shuffled.iloc[:num_train_samples]\n",
    "    val_set = df_shuffled.iloc[num_train_samples:num_train_samples + num_val_samples]\n",
    "    test_set = df_shuffled.iloc[num_train_samples + num_val_samples:]\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "\n",
    "def split_data_by_rate(data):\n",
    "    # 3. 保存到文件中，文本和图像一一对应。\n",
    "    # 划分训练和测试数据集，要求训练集和测试集中的正负类的分布差不多，\n",
    "    # 其中 文本 ID 和图像ID一致，也对应上文本的存储位置。\n",
    "    df_shuffled = data.sample(frac=1.0, random_state=42)\n",
    "    data_size = data.shape[0]\n",
    "    \n",
    "    # 计算训练集和测试集的数量\n",
    "    num_train_samples = int(0.8 * data_size)\n",
    "    num_val_samples = int(0.1 * data_size)\n",
    "    num_test_samples = data_size - num_train_samples - num_val_samples\n",
    "    # 分割数据集\n",
    "    \n",
    "    train_set = df_shuffled.iloc[:num_train_samples]\n",
    "    val_set = df_shuffled.iloc[num_train_samples:num_train_samples + num_val_samples]\n",
    "    test_set = df_shuffled.iloc[num_train_samples + num_val_samples:]\n",
    "    return train_set, val_set, test_set\n",
    "    \n",
    "    \n",
    "    # 分割数据集\n",
    "    \n",
    "    train_set = df_shuffled.iloc[:num_train_samples]\n",
    "    val_set = df_shuffled.iloc[num_train_samples:num_train_samples + num_val_samples]\n",
    "    test_set = df_shuffled.iloc[num_train_samples + num_val_samples:]\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "\n",
    "data_real_news = keep_data[keep_data.label=='real']\n",
    "data_fake_news = keep_data[keep_data.label=='fake']\n",
    "set_len = min(data_real_news.shape[0], data_fake_news.shape[0])\n",
    "#real_train_data ,real_val_data ,real_test_data = split_data(data_real_news)\n",
    "#fake_train_data ,fake_val_data ,fake_test_data = split_data(data_fake_news)\n",
    "\n",
    "real_train_data ,real_val_data ,real_test_data = split_data(data_real_news[:set_len])\n",
    "fake_train_data ,fake_val_data ,fake_test_data = split_data(data_fake_news[:set_len])\n",
    "\n",
    "\n",
    "train_set = pd.concat([real_train_data,fake_train_data]).sample(frac=1.0, random_state=42)\n",
    "val_set = pd.concat([real_val_data,fake_val_data]).sample(frac=1.0, random_state=42)\n",
    "test_set = pd.concat([real_test_data,fake_test_data]).sample(frac=1.0, random_state=42)\n",
    "\n",
    "\n",
    "train_set['label'].value_counts(),val_set['label'].value_counts(),test_set['label'].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fake    80\n",
       " real    80\n",
       " Name: label, dtype: int64,\n",
       " fake    80\n",
       " real    80\n",
       " Name: label, dtype: int64,\n",
       " fake    163\n",
       " real    163\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:50.810325Z",
     "start_time": "2024-08-07T05:28:50.800988Z"
    }
   },
   "source": "train_set.to_json(\"./gossipcop_v3_keep_data_in_proper_length_train.json\", orient=\"records\", indent=4,)",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:50.820199Z",
     "start_time": "2024-08-07T05:28:50.811668Z"
    }
   },
   "source": "val_set.to_json(\"./gossipcop_v3_keep_data_in_proper_length_valid.json\", orient=\"records\", indent=4,)",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:28:50.835277Z",
     "start_time": "2024-08-07T05:28:50.821289Z"
    }
   },
   "cell_type": "code",
   "source": "test_set.to_json(\"./gossipcop_v3_keep_data_in_proper_length_test.json\", orient=\"records\", indent=4,)",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yj_c2dsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
