{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T07:36:10.984690Z",
     "start_time": "2024-08-12T07:36:10.981858Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import tqdm"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T07:36:31.492208Z",
     "start_time": "2024-08-12T07:36:31.307344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def concat_txt(dir_path):\n",
    "    \"\"\"将原数据集中已经拆分完成的数据还原\"\"\"\n",
    "    rumor_file_suffix = '_rumor.txt'\n",
    "    nonrumor_file_suffix = '_nonrumor.txt'\n",
    "    files = os.listdir(dir_path)\n",
    "    file_prefix = dir_path + '/'\n",
    "    \n",
    "    rumor_file = file_prefix + 'rumor.txt'\n",
    "    nonrumor_file = file_prefix + 'nonrumor.txt'\n",
    "    for file in files:\n",
    "        with open(file_prefix + file, 'r') as f:\n",
    "            if file.endswith(rumor_file_suffix):\n",
    "                with open(rumor_file, 'a') as f1:\n",
    "                    f1.write(f.read())\n",
    "            if file.endswith(nonrumor_file_suffix):\n",
    "                with open(nonrumor_file, 'a') as f1:\n",
    "                    f1.write(f.read())\n",
    "\n",
    "def file2list(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "dir_path = './tweets'\n",
    "concat_txt(dir_path)\n",
    "rumor_list = file2list(dir_path + '/rumor.txt')\n",
    "nonrumor_list = file2list(dir_path + '/nonrumor.txt')\n",
    "\n",
    "len(rumor_list)//3,len(nonrumor_list)//3"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4748, 4779)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T07:37:15.858906Z",
     "start_time": "2024-08-12T07:37:15.018962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def has_image(imageUrls,image_set):\n",
    "    \"\"\"content为三行数据\"\"\"\n",
    "    images = imageUrls.split('|')\n",
    "    for image in images: # 遍历该新闻相关的图片\n",
    "        img = image.split('/')[-1]\n",
    "        if img in image_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def filter_data(data,image_set):\n",
    "    result = []\n",
    "    n_lines = len(data)\n",
    "    for idx in tqdm.tqdm(range(2, n_lines, 3)):\n",
    "        text = data[idx].strip()\n",
    "        if has_image(data[idx-1],image_set) and text:\n",
    "            result += data[idx-2:idx+1]\n",
    "    return result\n",
    "\n",
    "rumor_image_set = os.listdir('./rumor_images/')\n",
    "nonrumor_image_set = os.listdir('./nonrumor_images/')\n",
    "\n",
    "rumor_list = filter_data(rumor_list,rumor_image_set)\n",
    "nonrumor_list = filter_data(nonrumor_list,nonrumor_image_set)\n",
    "len(rumor_list)//3,len(nonrumor_list)//3"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4748/4748 [00:00<00:00, 25112.39it/s]\n",
      "100%|██████████| 4779/4779 [00:00<00:00, 7925.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4211, 3642)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T07:37:31.374039Z",
     "start_time": "2024-08-12T07:37:31.368954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_data(data):\n",
    "    train_lines = 80 * 3\n",
    "    valid_lines = 80 * 3\n",
    "    return data[:train_lines] , data[train_lines:train_lines + valid_lines], data[train_lines + valid_lines:]\n",
    "\n",
    "train_real, valid_real, test_real = split_data(nonrumor_list)\n",
    "train_fake, valid_fake, test_fake = split_data(rumor_list)\n",
    "print(\"train: real {}, fake: {}\".format(len(train_real)//3, len(train_fake)//3))\n",
    "print(\"valid: real {}, fake: {}\".format(len(valid_real)//3, len(valid_fake)//3))\n",
    "print(\"test: real {}, fake: {}\".format(len(test_real)//3, len(test_fake)//3))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: real 80, fake: 80\n",
      "valid: real 80, fake: 80\n",
      "test: real 3482, fake: 4051\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T07:37:35.682597Z",
     "start_time": "2024-08-12T07:37:35.578236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def list2file(file, list):\n",
    "    with open(file, 'w') as f:\n",
    "        for item in list:\n",
    "            f.write(item)\n",
    "\n",
    "\n",
    "list2file(dir_path + '/train_nonrumor.txt', train_real),list2file(dir_path + '/train_rumor.txt', train_fake)\n",
    "list2file(dir_path + '/valid_nonrumor.txt', valid_real),list2file(dir_path + '/valid_rumor.txt', valid_fake)\n",
    "list2file(dir_path + '/test_nonrumor.txt', test_real),list2file(dir_path + '/test_rumor.txt', test_fake)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yj_c2dsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
